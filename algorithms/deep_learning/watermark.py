import torch
import torch.nn.functional as F
import numpy as np
import math
from pathlib import Path
from typing import Union, Tuple, Dict, Optional

from .encoder import AdvVectorEncoder
from .decoder import AdvVectorDecoder


def get_adaptive_model_params(vec_dim: int, msg_len: int):
    base_capacity = vec_dim * msg_len  # ä¿¡æ¯å®¹é‡åŸºå‡†

    # è‡ªé€‚åº”è®¡ç®—æ¨¡å‹æ·±åº¦ (6-12å±‚)
    # ä½ç»´å‘é‡éœ€è¦æ›´æ·±çš„ç½‘ç»œæ¥æå–ç‰¹å¾
    depth = max(6, min(12, int(6 + 4 * (256 / max(vec_dim, 64)))))

    # è‡ªé€‚åº”è®¡ç®—éšå±‚å€æ•° (4-8å€)
    # ç¡®ä¿éšå±‚å¤§å°è‡³å°‘ä¸ºæ¶ˆæ¯é•¿åº¦çš„16å€ä»¥æä¾›è¶³å¤Ÿè¡¨è¾¾èƒ½åŠ›
    min_hidden = msg_len * 16
    hidden_mul = max(4, min(8, int(min_hidden / vec_dim) + 2))

    # è‡ªé€‚åº”è®¡ç®—æ‰°åŠ¨å¼ºåº¦
    # ä½ç»´å‘é‡éœ€è¦æ›´å°çš„æ‰°åŠ¨ä»¥ä¿æŒç¨³å®šæ€§
    delta_scale = max(0.01, min(0.03, 0.02 * math.sqrt(vec_dim / 256)))

    # è‡ªé€‚åº”è®¡ç®—dropoutç‡
    # ä½ç»´å‘é‡ç”¨æ›´å°‘dropouté¿å…æ¬ æ‹Ÿåˆ
    dropout = max(0.02, min(0.15, 0.1 * (vec_dim / 384)))

    return {
        'depth': depth,
        'hidden_mul': hidden_mul,
        'delta_scale': delta_scale,
        'dropout': dropout,
        'capacity_ratio': base_capacity / (vec_dim * vec_dim)  # ç”¨äºåç»­è°ƒæ•´
    }


class VectorWatermark:
    """å‘é‡æ°´å°å¤„ç†ç±»ï¼šåŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œæä¾›ç¼–ç å’Œè§£ç åŠŸèƒ½"""

    def __init__(
            self,
            vec_dim: int,
            msg_len: int,
            model_path: Optional[str] = None,
            device: Optional[str] = None,
    ) -> None:
        """
        åˆå§‹åŒ–å‘é‡æ°´å°å¤„ç†å™¨
        
        å‚æ•°:
            vec_dim: å‘é‡ç»´åº¦
            msg_len: æ¶ˆæ¯é•¿åº¦ï¼ˆæ¯”ç‰¹æ•°ï¼‰ï¼Œé»˜è®¤24ä½ï¼ˆ4ä½ç´¢å¼•+4ä½CRC+16ä½è½½è·ï¼‰
            model_path: é¢„è®­ç»ƒæ¨¡å‹æƒé‡è·¯å¾„
            device: è®¡ç®—è®¾å¤‡ï¼ŒNone æ—¶è‡ªåŠ¨é€‰æ‹©
        """
        # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
        if device is None:
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = device

        self.vec_dim = vec_dim
        self.msg_len = msg_len

        # ä½¿ç”¨ä¸è®­ç»ƒæ—¶å®Œå…¨ç›¸åŒçš„è‡ªé€‚åº”å‚æ•°è®¡ç®—
        model_params = get_adaptive_model_params(vec_dim, msg_len)
        self.depth = model_params['depth']
        self.hidden_mul = model_params['hidden_mul']
        self.delta_scale = model_params['delta_scale']
        self.p_drop = model_params['dropout']

        print(f"ğŸ”§ è‡ªé€‚åº”å‚æ•°é…ç½® (ç»´åº¦: {vec_dim}):")
        print(f"  æ¨¡å‹æ·±åº¦: {self.depth}, éšå±‚å€æ•°: {self.hidden_mul}")
        print(f"  æ‰°åŠ¨å¼ºåº¦: {self.delta_scale:.4f}, Dropout: {self.p_drop:.3f}")

        # ä½¿ç”¨è®¡ç®—å‡ºçš„å‚æ•°åˆå§‹åŒ–æ¨¡å‹
        self.encoder = AdvVectorEncoder(
            self.vec_dim,
            self.msg_len,
            depth=self.depth,
            hidden_mul=self.hidden_mul,
            delta_scale=self.delta_scale
        )
        self.decoder = AdvVectorDecoder(
            self.vec_dim,
            self.msg_len,
            depth=self.depth,
            hidden_mul=self.hidden_mul,
            p_drop=self.p_drop
        )

        # å°†æ¨¡å‹ç§»è‡³æŒ‡å®šè®¾å¤‡
        self.encoder.to(self.device)
        self.decoder.to(self.device)

        # å¦‚æœæä¾›äº†æ¨¡å‹è·¯å¾„ï¼Œåˆ™åŠ è½½æƒé‡
        if model_path:
            self.load_model(model_path)

        # é»˜è®¤è¯„ä¼°æ¨¡å¼
        self.encoder.eval()
        self.decoder.eval()

    def load_model(self, model_path: str) -> None:
        """
        åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æƒé‡
        
        å‚æ•°:
            model_path: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
        """
        model_path = Path(model_path)
        if not model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {model_path}")

        # åœ¨load_modelæ–¹æ³•ä¸­ä¿®æ”¹:
        checkpoint = torch.load(model_path, map_location=self.device, weights_only=True)

        # æ£€æŸ¥é¢„æœŸçš„é”®
        if 'enc' not in checkpoint or 'dec' not in checkpoint:
            raise ValueError(f"æ¨¡å‹æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘'enc'æˆ–'dec'é”®")

        try:
            self.encoder.load_state_dict(checkpoint['enc'])
            self.decoder.load_state_dict(checkpoint['dec'])
            print(f"æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡: {model_path}")
        except Exception as e:
            raise RuntimeError(f"åŠ è½½æ¨¡å‹æƒé‡å¤±è´¥: {str(e)}")

    def generate_message(self, batch_size: int = 1) -> torch.Tensor:
        """
        æŒ‰ç…§datasetæ ¼å¼ç”Ÿæˆæ¶ˆæ¯ï¼š4ä½ç´¢å¼• + 4ä½CRC + 16ä½è½½è·
        
        å‚æ•°:
            batch_size: æ‰¹é‡å¤§å°
            
        è¿”å›:
            æ¶ˆæ¯å¼ é‡ï¼Œå½¢çŠ¶ (batch_size, 24)
        """
        messages = []

        for _ in range(batch_size):
            # 1) éšæœºé€‰ä¸€ä¸ªå—ç´¢å¼• k âˆˆ [0,16)
            k = np.random.randint(0, 16)
            idx_bits = [(k >> i) & 1 for i in reversed(range(4))]  # MSB first

            # 2) è®¡ç®— 4 bit CRC-4 æ ¡éªŒï¼ˆå¤šé¡¹å¼ 0x3ï¼‰
            reg = 0
            for bit in idx_bits:
                reg ^= (bit << 3)
                for _ in range(4):
                    if reg & 0x8:
                        reg = ((reg << 1) & 0xF) ^ 0x3
                    else:
                        reg = (reg << 1) & 0xF
            crc_bits = [(reg >> i) & 1 for i in reversed(range(4))]

            # 3) éšæœºç”Ÿæˆ 16 bit payload
            payload = np.random.randint(0, 2, size=(16,), dtype=np.uint8).tolist()

            # 4) æ‹¼æˆ 24 bit æ¶ˆæ¯
            msg_bits = idx_bits + crc_bits + payload
            messages.append(msg_bits)

        return torch.tensor(messages, dtype=torch.float32, device=self.device)

    def encode(
            self,
            cover_vec: Union[torch.Tensor, np.ndarray],
            message: Union[torch.Tensor, np.ndarray, None] = None,
            random_msg: bool = False
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å°†æ¶ˆæ¯ç¼–ç åˆ°è½½ä½“å‘é‡ä¸­
        
        å‚æ•°:
            cover_vec: è½½ä½“å‘é‡ï¼Œå½¢çŠ¶ (batch_size, vec_dim) 
            message: å¾…ç¼–ç æ¶ˆæ¯ï¼Œå½¢çŠ¶ (batch_size, msg_len)ï¼Œå€¼ä¸º0/1
                     å¦‚æœä¸ºNoneä¸”random_msg=Trueï¼Œåˆ™ç”Ÿæˆéšæœºæ¶ˆæ¯
            random_msg: æ˜¯å¦ç”Ÿæˆéšæœºæ¶ˆæ¯
            
        è¿”å›:
            Tuple[éšå†™å‘é‡, ç¼–ç çš„æ¶ˆæ¯]
        """
        # è½¬æ¢è¾“å…¥ç±»å‹
        if isinstance(cover_vec, np.ndarray):
            cover_vec = torch.from_numpy(cover_vec)

        # ç¡®ä¿è¾“å…¥æ˜¯æµ®ç‚¹ç±»å‹
        cover_vec = cover_vec.float().to(self.device)

        # å¤„ç†è¾“å…¥ç»´åº¦
        if cover_vec.dim() == 1:
            cover_vec = cover_vec.unsqueeze(0)  # æ·»åŠ æ‰¹æ¬¡ç»´åº¦

        batch_size = cover_vec.shape[0]

        # å¤„ç†æ¶ˆæ¯
        if message is None:
            if random_msg:
                # ç”Ÿæˆç¬¦åˆæŒ‡å®šæ ¼å¼çš„éšæœºæ¶ˆæ¯
                message = self.generate_message(batch_size)
            else:
                raise ValueError("å¿…é¡»æä¾›æ¶ˆæ¯æˆ–è®¾ç½® random_msg=True")
        elif isinstance(message, np.ndarray):
            message = torch.from_numpy(message).float().to(self.device)
        else:
            message = message.float().to(self.device)

        # ç¡®ä¿æ¶ˆæ¯å½¢çŠ¶æ­£ç¡®
        if message.dim() == 1:
            message = message.unsqueeze(0)

        # å­˜å‚¨åŸå§‹å‘é‡çš„èŒƒæ•°ï¼Œç”¨äºåç»­æ¢å¤
        original_norms = torch.norm(cover_vec, p=2, dim=1, keepdim=True)

        # å¯¹è¾“å…¥å‘é‡è¿›è¡ŒL2å½’ä¸€åŒ–
        normalized_cover = F.normalize(cover_vec, p=2, dim=1)

        # ç¼–ç è¿‡ç¨‹
        with torch.no_grad():
            normalized_stego = self.encoder(normalized_cover, message)

        # åå½’ä¸€åŒ–ï¼Œæ¢å¤åŸå§‹èŒƒæ•°
        stego_vec = normalized_stego * original_norms

        return stego_vec, message

    def decode(
            self,
            stego_vec: Union[torch.Tensor, np.ndarray]
    ) -> torch.Tensor:
        """
        ä»éšå†™å‘é‡ä¸­è§£ç æ¶ˆæ¯
        
        å‚æ•°:
            stego_vec: éšå†™å‘é‡ï¼Œå½¢çŠ¶ (batch_size, vec_dim)
            
        è¿”å›:
            æå–çš„æ¶ˆæ¯ï¼Œå½¢çŠ¶ä¸º (batch_size, msg_len)ï¼Œå€¼ä¸º0/1
        """
        # è½¬æ¢è¾“å…¥ç±»å‹
        if isinstance(stego_vec, np.ndarray):
            stego_vec = torch.from_numpy(stego_vec)

        # ç¡®ä¿è¾“å…¥æ˜¯æµ®ç‚¹ç±»å‹
        stego_vec = stego_vec.float().to(self.device)

        # å¤„ç†è¾“å…¥ç»´åº¦
        if stego_vec.dim() == 1:
            stego_vec = stego_vec.unsqueeze(0)  # æ·»åŠ æ‰¹æ¬¡ç»´åº¦

        # å¯¹è¾“å…¥å‘é‡è¿›è¡ŒL2å½’ä¸€åŒ–
        normalized_stego = F.normalize(stego_vec, p=2, dim=1)

        # è§£ç è¿‡ç¨‹
        with torch.no_grad():
            logits = self.decoder(normalized_stego)
            message = torch.sigmoid(logits) > 0.5

        return message.float()

    def compute_ber(
            self,
            original_msg: torch.Tensor,
            decoded_msg: torch.Tensor
    ) -> float:
        """
        è®¡ç®—æ¯”ç‰¹é”™è¯¯ç‡ (BER)
        
        å‚æ•°:
            original_msg: åŸå§‹æ¶ˆæ¯
            decoded_msg: è§£ç çš„æ¶ˆæ¯
            
        è¿”å›:
            æ¯”ç‰¹é”™è¯¯ç‡ï¼Œå–å€¼èŒƒå›´ [0, 1]
        """
        if original_msg.shape != decoded_msg.shape:
            raise ValueError(f"æ¶ˆæ¯å½¢çŠ¶ä¸åŒ¹é…: {original_msg.shape} vs {decoded_msg.shape}")

        # è®¡ç®—ä¸åŒ¹é…çš„æ¯”ç‰¹å æ¯”
        ber = (decoded_msg != original_msg).float().mean().item()
        return ber

    def watermark_vector(
            self,
            cover_vec: Union[torch.Tensor, np.ndarray],
            message: Union[torch.Tensor, np.ndarray, None] = None,
            return_numpy: bool = False
    ) -> Union[torch.Tensor, np.ndarray]:
        """
        å®Œæ•´çš„æ°´å°æ·»åŠ è¿‡ç¨‹
        
        å‚æ•°:
            cover_vec: è½½ä½“å‘é‡
            message: æ°´å°æ¶ˆæ¯ï¼Œå¦‚æœä¸ºNoneåˆ™éšæœºç”Ÿæˆç¬¦åˆæ ¼å¼çš„æ¶ˆæ¯
            return_numpy: æ˜¯å¦è¿”å›numpyæ•°ç»„
            
        è¿”å›:
            éšå†™å‘é‡
        """
        stego_vec, _ = self.encode(cover_vec, message, random_msg=(message is None))

        if return_numpy and isinstance(stego_vec, torch.Tensor):
            return stego_vec.cpu().numpy()
        return stego_vec

    def extract_watermark(
            self,
            stego_vec: Union[torch.Tensor, np.ndarray],
            return_numpy: bool = False
    ) -> Union[torch.Tensor, np.ndarray]:
        """
        ä»æ°´å°å‘é‡ä¸­æå–æ¶ˆæ¯
        
        å‚æ•°:
            stego_vec: éšå†™å‘é‡
            return_numpy: æ˜¯å¦è¿”å›numpyæ•°ç»„
            
        è¿”å›:
            æå–çš„æ¶ˆæ¯
        """
        message = self.decode(stego_vec)

        if return_numpy and isinstance(message, torch.Tensor):
            return message.cpu().numpy()
        return message

    def verify_message(self, message: torch.Tensor) -> Union[bool, list]:
        """
        éªŒè¯æ¶ˆæ¯çš„CRCæ ¡éªŒå’Œæ˜¯å¦æ­£ç¡®
        
        å‚æ•°:
            message: å½¢çŠ¶ä¸º(msg_len,)æˆ–(batch_size, msg_len)çš„æ¶ˆæ¯
            
        è¿”å›:
            æ ¡éªŒæ˜¯å¦é€šè¿‡çš„å¸ƒå°”å€¼æˆ–å¸ƒå°”å€¼åˆ—è¡¨
        """
        if message.dim() == 1:
            message = message.unsqueeze(0)

        batch_size = message.shape[0]
        results = []

        for i in range(batch_size):
            msg = message[i]
            idx_bits = msg[:4].cpu().int().tolist()
            crc_bits = msg[4:8].cpu().int().tolist()

            # è®¡ç®—CRCæ ¡éªŒ
            reg = 0
            for bit in idx_bits:
                reg ^= (bit << 3)
                for _ in range(4):
                    if reg & 0x8:
                        reg = ((reg << 1) & 0xF) ^ 0x3
                    else:
                        reg = (reg << 1) & 0xF
            expected_crc = [(reg >> j) & 1 for j in reversed(range(4))]

            # æ¯”è¾ƒè®¡ç®—çš„CRCå’Œè§£ç çš„CRC
            is_valid = (expected_crc == crc_bits)
            results.append(is_valid)

        return results[0] if len(results) == 1 else results
